---
title: "TSA: Forecasting Competition Instructions"
author: "Sai Powar & Vinny Whatley"
date: "03/20/2024"
output: pdf_document
always_allow_html: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

```{r package, message=FALSE}
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(cowplot)
#install.packages("smooth")
library(smooth)
```

```{r}
#change file path for data as necessary
raw_load <- read.csv(file="Data_TOPOST/converting files to csv/temperature.csv", header = TRUE, dec = ".", sep=",") 

raw_temp <- read.csv(file="Data_TOPOST/converting files to csv/temperature.csv", header = TRUE, dec = ".", sep=",")

raw_humidity <- read.csv(file="Data_TOPOST/converting files to csv/relative_humidity.csv", header = TRUE, dec = ".", sep=",")
```

```{r}
#pratice
raw_load <- raw_load %>%
  drop_na() %>%
  mutate(date = dmy(date)) %>%
  mutate(date = format(date, "%m-%d-%Y"))  # Change date format to mm-dd-yyyy

# Pivot the data
raw_load_gather <- raw_load %>%
  pivot_longer(cols = starts_with("t_ws"), names_to = "Hour", values_to = "Load")

# Convert Hour column to numeric
raw_load_gather <- raw_load_gather %>%
  mutate(Hour = as.numeric(gsub("t_ws", "", Hour)))

# Group by date and hour, then calculate the mean load
load_hourly <- raw_load_gather %>%
  group_by(date, Hour) %>%
  summarise(hourly_mean_load = mean(Load))
```


```{r}
#cleaning more and calculating daily averages

# Assuming 'date' column is in mm/dd/yyyy format
raw_load <- raw_load %>%
  drop_na() %>%
  mutate(date = dmy(date)) %>%
  mutate(date = format(date, "%m-%d-%Y"))  # Change date format to mm-dd-yyyy

raw_load_gather <- raw_load %>%
  pivot_longer(cols=hr, names_to = "Hour", values_to = "Load")

load_daily <- raw_load_gather %>%
  filter( !is.na(Load)) %>%
  group_by(date) %>%
  summarise( daily_mean_load = mean(Load)) 


```

```{r}
#dont run this 

# Step 1: Pivot the data
raw_load_gather <- raw_load %>%
  pivot_longer(cols = starts_with("hr"), names_to = "Hour", values_to = "Load")

# Step 2: Filter out rows with missing load values
filtered_data <- raw_load_gather %>%
  filter(!is.na(Load))

# Step 3 & 4: Group by date and calculate daily mean load
load_daily <- filtered_data %>%
  group_by(date) %>%
  summarise(daily_mean_load = mean(Load))

# Step 3 & 4: Group by date and calculate daily mean load
load_daily <- filtered_data %>%
  group_by(date)

# Assuming your data frame is called 'raw_load_pivot'
raw_load_pivot <- load_daily %>%
  mutate(avg_t_ws = rowMeans(select(., t_ws1:t_ws28), na.rm = TRUE))

```


```{r}
#cleaning and calculating daily temp averages

raw_temp_pivot <- raw_temp %>%
  pivot_longer(cols=t_ws1:t_ws28, names_to = "station", values_to = "temp") %>%
  mutate(date = dmy(date))

temp <- raw_temp_pivot %>%
  filter(!is.na(temp)) %>%
  group_by(date) %>%
  summarise(daily_temp = mean(temp)) %>%
  drop_na()

#cleaning and calculating daily humidity

raw_hum_pivot <- raw_humidity %>%
  pivot_longer(cols=rh_ws1:rh_ws28, names_to = "station", values_to = "humidity") %>%
  mutate(date = dmy(date))

humidity <- raw_hum_pivot %>%
  filter(!is.na(humidity)) %>%
  group_by(date) %>%
  summarise(daily_humidity = mean(humidity))
```

```{r}
# Create a time series object using msts()
ts_load <- msts(load_hourly$hourly_mean_load, seasonal.periods = c(7,365.25), start = c(2005,1,1))
head(ts_load)
 
# Plot the time series
plot(ts_load, main = "Time Series Plot", xlab = "Time", ylab = "Value")

ts_temp <- msts(temp$daily_temp, seasonal.periods = c(7,365.25), start = c(2005,1,1))

ts_humidity <- msts(humidity$daily_humidity, seasonal.periods = c(7,365.25), start = c(2005,1,1))
```

```{r}
#pratice
class(subset_data)

arima_model <- auto.arima(subset_data)
```


```{r}
# Subset data from January 1st, 2005 to May 31st, 2011
subset_data <- window(ts_load, start = c(2005, 1), end = c(2011, 5))

frequency(subset_data)

# Fit ARIMA model
arima_model <- arima(subset_data, order = c(1, 0, 1), seasonal = c(1, 1, 1), 
                     xreg = NULL, include.mean = TRUE)


```


```{r}
# Generate the autocorrelation plot
autoplot(ts_load, series = "A")

# Generate the partial autocorrelation plot
autoplot(ts_load, series = "P")
```

Fit models to your dataset considering the period Jan 1st 2005 to May 31st 2011. 

```{r}

#plotting ACF and PACF
# Calculate ACF and PACF
acf_result <- Acf(ts_load, lag.max = 40, plot = FALSE)$acf
pacf_result <- Pacf(ts_load, lag.max = 40, plot = FALSE)$pacf

# Convert arrays to data frames
acf_df <- data.frame(Lag = 0:40, ACF = acf_result)
pacf_df <- data.frame(Lag = 0:40, PACF = pacf_result)

# Plot the ACF and PACF
plot_grid(
  autoplot(acf_df, aes(x = Lag, y = ACF)) +
    geom_hline(yintercept = 0, linetype = "dotted") +
    labs(title = "Autocorrelation Function (ACF)"),
  autoplot(pacf_df, aes(x = Lag, y = PACF)) +
    geom_hline(yintercept = 0, linetype = "dotted") +
    labs(title = "Partial Autocorrelation Function (PACF)"),
  ncol = 2
)


plot_grid(
  autoplot(Acf(ts_load,lag.max=40,plot=FALSE)),
  autoplot(Pacf(ts_load,lag.max=40,plot=FALSE)))

ACF_Plot <- Acf(ts_load, lag = 40, plot = TRUE)
PACF_Plot <- Pacf(ts_load, lag = 40)

#ACF has slow decats_load#ACF has slow decay, and PACF cuts off at lag 1 and is negative = AR process
#there are spikes at seasonal lags as well

```

```{r}
#trend tests
SMKtest <- SeasonalMannKendall(ts_load)
print("Results for Seasonal Mann Kendall /n")
print(summary(SMKtest))

print("Results for ADF test/n")
print(adf.test(ts_load,alternative = "stationary"))

#SMK - S is positive, so there is an increasing trend. p-value<0.05 so there is a significant trend.
#ADF - p-value<0.05 so null hypothesis is rejected and series has deterministic/stationary trend. 

```

```{r}
#decomposing the series

decomposed <- decompose(ts_load)

seasonal <- decomposed$seasonal
trend <- decomposed$trend
random <- decomposed$random
```

```{r}
autoplot(random)+
  autolayer(ts_load)

plot_grid(
  autoplot(Acf(ts_load, lag = 40, plot=FALSE), 
                main = "Orginal Load"),
  autoplot(Acf(random, lag = 40, plot=FALSE),  
                  main = "Deseason Load")
)
```

```{r}

#creating subset for training purposes

n_for = 30

ts_load_train <- subset(ts_load,end = length(ts_load)-n_for)
ts_load_test <- subset(ts_load,start= length(ts_load)-n_for+1)

autoplot(ts_load_train)
autoplot(ts_load_test)
```

```{r}

#creating subset for training purposes

n_for = 30

ts_load_train <- subset(ts_load,end = length(ts_load)-n_for)
ts_load_test <- subset(ts_load,start= length(ts_load)-n_for+1)

autoplot(ts_load_train)
autoplot(ts_load_test)
```

```{r}
#ARIMA model for training (Jan 1st 2005 to May 31st 2011)

ts_load_train <- msts(ts_load, seasonal.periods = c(12, 365.25), start = c(2005, 1), frequency = 365.25)
ts_load_train <- msts(ts_load, seasonal.periods = c(12, 365.25), start = c(2005, 1))
Model1_train<-auto.arima(ts_load_train)
Model1_train <- auto.arima(ts_load_train, D = c(1, 1))


length(c(1, 1))


ts_load_train_ts <- ts(ts_load_train, start = start(ts_load_train), frequency = frequency(ts_load_train))
Model1_train <- auto.arima(ts_load_train_ts, D = c(1, 1))
```

